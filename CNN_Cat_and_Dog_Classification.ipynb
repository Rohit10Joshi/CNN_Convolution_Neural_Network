{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKepIEukrnNU",
        "outputId": "f21eab01-a286-4a7b-f2a4-8af408c2098c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.6)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all the necessary libraries\n",
        "import opendatasets as od\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "VF0XzilDr15K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/tongpython/cat-and-dog\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjj2-8zUr7rq",
        "outputId": "00936bc1-c0c5-4741-c6d5-c02a9a868f63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: rohitjoshi101096\n",
            "Your Kaggle Key: ··········\n",
            "Downloading cat-and-dog.zip to ./cat-and-dog\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 218M/218M [00:10<00:00, 20.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the path to dataset\n",
        "train_dir = '/content/cat-and-dog/training_set/training_set'\n",
        "test_dir = '/content/cat-and-dog/test_set/test_set'\n",
        "\n",
        "# Parameters\n",
        "batch_size = 32\n",
        "image_size = (64,64)\n",
        "input_shape = (64,64,3)  # 3 for RGB images"
      ],
      "metadata": {
        "id": "KAzwS82Mr7vO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "iEEPdJ6fGBaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNlOWV7CsbT6",
        "outputId": "c0993057-27ea-48d0-ea6d-7ef2953c9850"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8005 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating and training the CNN model"
      ],
      "metadata": {
        "id": "PTRhwtrxGazp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(512, activation='relu'),  # fully connected layes\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW18nOLjsgZP",
        "outputId": "cafccbd4-d093-410e-e963-5e3bfe8f485e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "250/250 [==============================] - 22s 61ms/step - loss: 0.6874 - accuracy: 0.5348 - val_loss: 0.6742 - val_accuracy: 0.5580\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.6554 - accuracy: 0.6054 - val_loss: 0.6398 - val_accuracy: 0.6349\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 16s 65ms/step - loss: 0.6260 - accuracy: 0.6556 - val_loss: 0.6311 - val_accuracy: 0.6429\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.5918 - accuracy: 0.6848 - val_loss: 0.5677 - val_accuracy: 0.7083\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 14s 58ms/step - loss: 0.5464 - accuracy: 0.7244 - val_loss: 0.5453 - val_accuracy: 0.7227\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.4982 - accuracy: 0.7543 - val_loss: 0.4797 - val_accuracy: 0.7773\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.4432 - accuracy: 0.7978 - val_loss: 0.4747 - val_accuracy: 0.7788\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 14s 58ms/step - loss: 0.4095 - accuracy: 0.8130 - val_loss: 0.4223 - val_accuracy: 0.8120\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 15s 59ms/step - loss: 0.3620 - accuracy: 0.8398 - val_loss: 0.4332 - val_accuracy: 0.8061\n",
            "Epoch 10/20\n",
            "250/250 [==============================] - 16s 62ms/step - loss: 0.3057 - accuracy: 0.8679 - val_loss: 0.4087 - val_accuracy: 0.8170\n",
            "Epoch 11/20\n",
            "250/250 [==============================] - 15s 61ms/step - loss: 0.2806 - accuracy: 0.8790 - val_loss: 0.4099 - val_accuracy: 0.8279\n",
            "Epoch 12/20\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.2482 - accuracy: 0.8915 - val_loss: 0.4505 - val_accuracy: 0.8130\n",
            "Epoch 13/20\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.2207 - accuracy: 0.9051 - val_loss: 0.4253 - val_accuracy: 0.8363\n",
            "Epoch 14/20\n",
            "250/250 [==============================] - 17s 69ms/step - loss: 0.1974 - accuracy: 0.9222 - val_loss: 0.4422 - val_accuracy: 0.8299\n",
            "Epoch 15/20\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.1605 - accuracy: 0.9337 - val_loss: 0.5970 - val_accuracy: 0.8135\n",
            "Epoch 16/20\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.1551 - accuracy: 0.9407 - val_loss: 0.4429 - val_accuracy: 0.8304\n",
            "Epoch 17/20\n",
            "250/250 [==============================] - 17s 70ms/step - loss: 0.1263 - accuracy: 0.9508 - val_loss: 0.5001 - val_accuracy: 0.8219\n",
            "Epoch 18/20\n",
            "250/250 [==============================] - 15s 58ms/step - loss: 0.1088 - accuracy: 0.9550 - val_loss: 0.5368 - val_accuracy: 0.8398\n",
            "Epoch 19/20\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.1123 - accuracy: 0.9552 - val_loss: 0.6331 - val_accuracy: 0.8234\n",
            "Epoch 20/20\n",
            "250/250 [==============================] - 15s 60ms/step - loss: 0.1054 - accuracy: 0.9612 - val_loss: 0.6218 - val_accuracy: 0.8229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cheking predicition for Cat image"
      ],
      "metadata": {
        "id": "VRJVrFq6G1UY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Function to preprocess the image for prediction\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(64,64))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array / 255.\n",
        "\n",
        "# Path to the image you want to make predictions on\n",
        "image_path = '/content/cat-and-dog/test_set/test_set/cats/cat.4011.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "processed_image = preprocess_image(image_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(processed_image)\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['Cat', 'Dog']\n",
        "\n",
        "# Display the prediction\n",
        "predicted_class = class_labels[int(np.round(prediction[0]))]\n",
        "print(f'The image is predicted as: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zy7sToHsmMP",
        "outputId": "6b6289f8-3aee-4009-d887-7654c4dcd56b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 348ms/step\n",
            "The image is predicted as: Cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cheking predicition for Dog image"
      ],
      "metadata": {
        "id": "hNfV4sA5GtKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Function to preprocess the image for prediction\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(64,64))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array / 255.\n",
        "\n",
        "# Path to the image you want to make predictions on\n",
        "image_path = '/content/cat-and-dog/test_set/test_set/dogs/dog.4022.jpg'\n",
        "\n",
        "# Preprocess the image\n",
        "processed_image = preprocess_image(image_path)\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(processed_image)\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['Cat', 'Dog']\n",
        "\n",
        "# Display the prediction\n",
        "predicted_class = class_labels[int(np.round(prediction[0]))]\n",
        "print(f'The image is predicted as: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vja0TJ_wssdC",
        "outputId": "c79bb3cf-4887-4794-ecf3-684fffc3441f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "The image is predicted as: Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D-_jGRzMvJj_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}