{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W2KKTkpOemjU"
      },
      "outputs": [],
      "source": [
        "# importing all the necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(xtrain,ytrain),(xtest,ytest) = cifar10.load_data()  # loading the data"
      ],
      "metadata": {
        "id": "ZtT_T19SfC39"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7BcEaCYfip9",
        "outputId": "a6822188-960c-4a81-879a-6b791543c7dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing(normalizing) the xtrain and xtest\n",
        "\n",
        "xtrain = preprocess_input(xtrain[:2000])  # taking only 2000 images for training\n",
        "xtest = preprocess_input(xtest[:500])     # taking only 500 images for training\n",
        "\n",
        "ytrain = ytrain[:2000]\n",
        "ytest = ytest[:500]"
      ],
      "metadata": {
        "id": "E1ccgunlfxkJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrain[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "035N_HORovQJ",
        "outputId": "7d26dc86-bc09-4feb-9f2f-a9c4563c7a2d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.5372549 , -0.5137255 , -0.5058824 ],\n",
              "        [-0.6627451 , -0.6392157 , -0.64705884],\n",
              "        [-0.60784316, -0.62352943, -0.6627451 ],\n",
              "        ...,\n",
              "        [ 0.23921573,  0.03529418, -0.15294117],\n",
              "        [ 0.19215691, -0.01960784, -0.19999999],\n",
              "        [ 0.16078436, -0.02745098, -0.19215685]],\n",
              "\n",
              "       [[-0.8745098 , -0.84313726, -0.84313726],\n",
              "        [-1.        , -1.        , -1.        ],\n",
              "        [-0.85882354, -0.9372549 , -1.        ],\n",
              "        ...,\n",
              "        [-0.03529412, -0.3098039 , -0.5686275 ],\n",
              "        [-0.06666666, -0.3490196 , -0.60784316],\n",
              "        [-0.04313725, -0.31764704, -0.5529412 ]],\n",
              "\n",
              "       [[-0.8039216 , -0.8117647 , -0.8352941 ],\n",
              "        [-0.8745098 , -0.94509804, -1.        ],\n",
              "        [-0.6156863 , -0.7882353 , -0.9372549 ],\n",
              "        ...,\n",
              "        [-0.0745098 , -0.34117645, -0.60784316],\n",
              "        [-0.05882353, -0.34117645, -0.60784316],\n",
              "        [-0.14509803, -0.42745095, -0.67058825]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 0.6313726 ,  0.33333337, -0.24705881],\n",
              "        [ 0.5764706 ,  0.20000005, -0.73333335],\n",
              "        [ 0.5529412 ,  0.26274514, -0.79607844],\n",
              "        ...,\n",
              "        [ 0.254902  ,  0.04313731, -0.45098037],\n",
              "        [-0.56078434, -0.75686276, -0.94509804],\n",
              "        [-0.58431375, -0.73333335, -0.84313726]],\n",
              "\n",
              "       [[ 0.41176474,  0.09019613, -0.24705881],\n",
              "        [ 0.35686278, -0.03529412, -0.67058825],\n",
              "        [ 0.45882356,  0.12941182, -0.7647059 ],\n",
              "        ...,\n",
              "        [ 0.4431373 ,  0.16078436, -0.26274508],\n",
              "        [-0.23921567, -0.5137255 , -0.73333335],\n",
              "        [-0.3490196 , -0.58431375, -0.73333335]],\n",
              "\n",
              "       [[ 0.38823533,  0.12941182, -0.09019607],\n",
              "        [ 0.3176471 ,  0.01176476, -0.26274508],\n",
              "        [ 0.4039216 ,  0.11372554, -0.31764704],\n",
              "        ...,\n",
              "        [ 0.69411767,  0.4431373 ,  0.09803927],\n",
              "        [ 0.18431377, -0.0745098 , -0.34117645],\n",
              "        [-0.03529412, -0.27843136, -0.4352941 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'xtrain shape -', xtrain.shape)\n",
        "print(f'xtest shape -', xtest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssVu0fc2hmJX",
        "outputId": "bb8956d6-7e5b-4573-8e82-34c69a8d44f3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtrain shape - (2000, 32, 32, 3)\n",
            "xtest shape - (500, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the images as Inception model takes input size as (75,75,3) or more"
      ],
      "metadata": {
        "id": "DPcYdNYXLrxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def resize(images,new_size): #75\n",
        "  resized_images = []\n",
        "  for image in images:\n",
        "    resized_image = cv2.resize(image,(new_size,new_size))\n",
        "    # resized_image = cv2.resize(image,new_size)\n",
        "    resized_images.append(resized_image)\n",
        "  return np.array(resized_images)\n",
        "\n",
        "xtrain = resize(xtrain,75)\n",
        "xtest = resize(xtest,75)\n",
        "print(f'xtrain shape -', xtrain.shape)\n",
        "print(f'xtest shape -', xtest.shape)"
      ],
      "metadata": {
        "id": "aVhqP0jXhA6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c52069-90f8-46d0-e989-4e785f167f4b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xtrain shape - (2000, 75, 75, 3)\n",
            "xtest shape - (500, 75, 75, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing One Hot Encoding on label or output names"
      ],
      "metadata": {
        "id": "eFI7mWQbMGGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_sDbfQIlker",
        "outputId": "9031752e-902c-4288-c14c-f4cdcd6506ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain = to_categorical(ytrain)   # uses to_categorical to perform one hot encoder\n",
        "ytest = to_categorical(ytest)"
      ],
      "metadata": {
        "id": "WFIiVkvupCCN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpDdbNLUpOfu",
        "outputId": "2cd2ea30-2dc1-4870-dc98-8a983f20740d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCYZLDwwpaGP",
        "outputId": "ae5ee299-ba9d-4874-c552-e042d973d01d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the InceptionV3 model"
      ],
      "metadata": {
        "id": "k06FSW0MMixP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inceptionV3model = InceptionV3(weights = \"imagenet\",include_top = False,input_shape = (75,75,3))  # InceptionV3 block\n",
        "\n",
        "cnn_block = inceptionV3model.output  # CNN block\n",
        "\n",
        "flattenpart = GlobalAveragePooling2D()(cnn_block)  # flatten block\n",
        "\n",
        "# ANN block\n",
        "annpart = Dense(1924,activation = \"relu\")(flattenpart)\n",
        "hiddenann = Dense(520,activation = \"relu\")(annpart)\n",
        "outputlayer = Dense(10,activation = \"softmax\")(hiddenann)\n",
        "model = Model(inputs = inceptionV3model.input, outputs = outputlayer)\n",
        "\n",
        "# compiling the model\n",
        "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",metrics = [\"accuracy\"])\n",
        "model.fit(xtrain,ytrain, epochs = 200)"
      ],
      "metadata": {
        "id": "sdxWu9xtju51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14cfaa6-77a7-4979-bacb-193763c08c6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "63/63 [==============================] - 48s 102ms/step - loss: 2.1594 - accuracy: 0.2160\n",
            "Epoch 2/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 1.7641 - accuracy: 0.3485\n",
            "Epoch 3/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.6251 - accuracy: 0.4080\n",
            "Epoch 4/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.5459 - accuracy: 0.4445\n",
            "Epoch 5/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 1.5178 - accuracy: 0.4635\n",
            "Epoch 6/200\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 1.6993 - accuracy: 0.3745\n",
            "Epoch 7/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.6939 - accuracy: 0.3840\n",
            "Epoch 8/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.6826 - accuracy: 0.3735\n",
            "Epoch 9/200\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 1.8914 - accuracy: 0.2760\n",
            "Epoch 10/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 1.7045 - accuracy: 0.3750\n",
            "Epoch 11/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.5084 - accuracy: 0.4525\n",
            "Epoch 12/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 1.4215 - accuracy: 0.4765\n",
            "Epoch 13/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 1.4748 - accuracy: 0.4735\n",
            "Epoch 14/200\n",
            "63/63 [==============================] - 4s 71ms/step - loss: 1.5243 - accuracy: 0.4355\n",
            "Epoch 15/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 1.5463 - accuracy: 0.4275\n",
            "Epoch 16/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 1.4573 - accuracy: 0.4685\n",
            "Epoch 17/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.4888 - accuracy: 0.4615\n",
            "Epoch 18/200\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 1.4754 - accuracy: 0.4610\n",
            "Epoch 19/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 1.4954 - accuracy: 0.4460\n",
            "Epoch 20/200\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 1.5728 - accuracy: 0.4325\n",
            "Epoch 21/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.4107 - accuracy: 0.4735\n",
            "Epoch 22/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 1.3270 - accuracy: 0.5205\n",
            "Epoch 23/200\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 1.2882 - accuracy: 0.5360\n",
            "Epoch 24/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.4041 - accuracy: 0.4880\n",
            "Epoch 25/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.4730 - accuracy: 0.4710\n",
            "Epoch 26/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 1.8149 - accuracy: 0.3405\n",
            "Epoch 27/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 1.8491 - accuracy: 0.3040\n",
            "Epoch 28/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.7710 - accuracy: 0.3460\n",
            "Epoch 29/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 1.5116 - accuracy: 0.4360\n",
            "Epoch 30/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 1.4554 - accuracy: 0.4530\n",
            "Epoch 31/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 1.3444 - accuracy: 0.5065\n",
            "Epoch 32/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 1.4334 - accuracy: 0.4765\n",
            "Epoch 33/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 1.3406 - accuracy: 0.4955\n",
            "Epoch 34/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 1.2347 - accuracy: 0.5550\n",
            "Epoch 35/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 1.1800 - accuracy: 0.5765\n",
            "Epoch 36/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 1.0765 - accuracy: 0.5970\n",
            "Epoch 37/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 1.0128 - accuracy: 0.6280\n",
            "Epoch 38/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.8974 - accuracy: 0.6625\n",
            "Epoch 39/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.8167 - accuracy: 0.6985\n",
            "Epoch 40/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.7708 - accuracy: 0.7185\n",
            "Epoch 41/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.7716 - accuracy: 0.7255\n",
            "Epoch 42/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.7245 - accuracy: 0.7520\n",
            "Epoch 43/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.6492 - accuracy: 0.7725\n",
            "Epoch 44/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.6600 - accuracy: 0.7750\n",
            "Epoch 45/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.6522 - accuracy: 0.7750\n",
            "Epoch 46/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.7486 - accuracy: 0.7405\n",
            "Epoch 47/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5677 - accuracy: 0.8040\n",
            "Epoch 48/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.6020 - accuracy: 0.7950\n",
            "Epoch 49/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.7848 - accuracy: 0.7245\n",
            "Epoch 50/200\n",
            "63/63 [==============================] - 5s 77ms/step - loss: 1.0635 - accuracy: 0.6280\n",
            "Epoch 51/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 1.2174 - accuracy: 0.5785\n",
            "Epoch 52/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.6952 - accuracy: 0.3785\n",
            "Epoch 53/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 1.3868 - accuracy: 0.4890\n",
            "Epoch 54/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 1.2242 - accuracy: 0.5575\n",
            "Epoch 55/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.1118 - accuracy: 0.5815\n",
            "Epoch 56/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.0422 - accuracy: 0.6240\n",
            "Epoch 57/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 1.0347 - accuracy: 0.6270\n",
            "Epoch 58/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.9321 - accuracy: 0.6615\n",
            "Epoch 59/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.8730 - accuracy: 0.6940\n",
            "Epoch 60/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.7752 - accuracy: 0.7130\n",
            "Epoch 61/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6993 - accuracy: 0.7650\n",
            "Epoch 62/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.8652 - accuracy: 0.6910\n",
            "Epoch 63/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.7039 - accuracy: 0.7360\n",
            "Epoch 64/200\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.6568 - accuracy: 0.7685\n",
            "Epoch 65/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.5765 - accuracy: 0.8025\n",
            "Epoch 66/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.5382 - accuracy: 0.8180\n",
            "Epoch 67/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.5645 - accuracy: 0.8020\n",
            "Epoch 68/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.6061 - accuracy: 0.7820\n",
            "Epoch 69/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.5794 - accuracy: 0.8035\n",
            "Epoch 70/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.4166 - accuracy: 0.8505\n",
            "Epoch 71/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.4874 - accuracy: 0.8385\n",
            "Epoch 72/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.3818 - accuracy: 0.8710\n",
            "Epoch 73/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3238 - accuracy: 0.8860\n",
            "Epoch 74/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.3149 - accuracy: 0.8940\n",
            "Epoch 75/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.3748 - accuracy: 0.8680\n",
            "Epoch 76/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.4242 - accuracy: 0.8510\n",
            "Epoch 77/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2696 - accuracy: 0.9070\n",
            "Epoch 78/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.2325 - accuracy: 0.9185\n",
            "Epoch 79/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.2798 - accuracy: 0.9040\n",
            "Epoch 80/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.3231 - accuracy: 0.8920\n",
            "Epoch 81/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3036 - accuracy: 0.8940\n",
            "Epoch 82/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2712 - accuracy: 0.9120\n",
            "Epoch 83/200\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.2569 - accuracy: 0.9145\n",
            "Epoch 84/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.2054 - accuracy: 0.9275\n",
            "Epoch 85/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.6510 - accuracy: 0.7865\n",
            "Epoch 86/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.7181 - accuracy: 0.7610\n",
            "Epoch 87/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 1.0635 - accuracy: 0.6470\n",
            "Epoch 88/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.6322 - accuracy: 0.7805\n",
            "Epoch 89/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.4180 - accuracy: 0.8585\n",
            "Epoch 90/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.3735 - accuracy: 0.8710\n",
            "Epoch 91/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3201 - accuracy: 0.8920\n",
            "Epoch 92/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.2751 - accuracy: 0.9145\n",
            "Epoch 93/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.2441 - accuracy: 0.9175\n",
            "Epoch 94/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2160 - accuracy: 0.9305\n",
            "Epoch 95/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1909 - accuracy: 0.9355\n",
            "Epoch 96/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.2514 - accuracy: 0.9200\n",
            "Epoch 97/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2294 - accuracy: 0.9215\n",
            "Epoch 98/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.1632 - accuracy: 0.9460\n",
            "Epoch 99/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.1564 - accuracy: 0.9485\n",
            "Epoch 100/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.1715 - accuracy: 0.9440\n",
            "Epoch 101/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.1386 - accuracy: 0.9555\n",
            "Epoch 102/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.1288 - accuracy: 0.9545\n",
            "Epoch 103/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.1342 - accuracy: 0.9550\n",
            "Epoch 104/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2411 - accuracy: 0.9245\n",
            "Epoch 105/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.5990 - accuracy: 0.8035\n",
            "Epoch 106/200\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.5715 - accuracy: 0.8145\n",
            "Epoch 107/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.9385 - accuracy: 0.6995\n",
            "Epoch 108/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.8362 - accuracy: 0.7425\n",
            "Epoch 109/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.4320 - accuracy: 0.8680\n",
            "Epoch 110/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.2897 - accuracy: 0.9065\n",
            "Epoch 111/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.2439 - accuracy: 0.9170\n",
            "Epoch 112/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2081 - accuracy: 0.9380\n",
            "Epoch 113/200\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.1932 - accuracy: 0.9315\n",
            "Epoch 114/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 1.2742 - accuracy: 0.5880\n",
            "Epoch 115/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.9288 - accuracy: 0.6840\n",
            "Epoch 116/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.7685 - accuracy: 0.7405\n",
            "Epoch 117/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.6440 - accuracy: 0.7755\n",
            "Epoch 118/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3736 - accuracy: 0.8745\n",
            "Epoch 119/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.3631 - accuracy: 0.8715\n",
            "Epoch 120/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.2716 - accuracy: 0.9110\n",
            "Epoch 121/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.1800 - accuracy: 0.9380\n",
            "Epoch 122/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.5620 - accuracy: 0.8075\n",
            "Epoch 123/200\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.7673 - accuracy: 0.7560\n",
            "Epoch 124/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.8663 - accuracy: 0.7130\n",
            "Epoch 125/200\n",
            "63/63 [==============================] - 3s 52ms/step - loss: 0.4504 - accuracy: 0.8535\n",
            "Epoch 126/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.2999 - accuracy: 0.8985\n",
            "Epoch 127/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.2649 - accuracy: 0.9110\n",
            "Epoch 128/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.2090 - accuracy: 0.9285\n",
            "Epoch 129/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.2700 - accuracy: 0.9120\n",
            "Epoch 130/200\n",
            "63/63 [==============================] - 4s 61ms/step - loss: 0.3160 - accuracy: 0.9120\n",
            "Epoch 131/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.2542 - accuracy: 0.9095\n",
            "Epoch 132/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3224 - accuracy: 0.8850\n",
            "Epoch 133/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.1789 - accuracy: 0.9430\n",
            "Epoch 134/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.3478 - accuracy: 0.8930\n",
            "Epoch 135/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.5470 - accuracy: 0.8215\n",
            "Epoch 136/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.5685 - accuracy: 0.8270\n",
            "Epoch 137/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 1.2376 - accuracy: 0.5935\n",
            "Epoch 138/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.7316 - accuracy: 0.7585\n",
            "Epoch 139/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.3917 - accuracy: 0.8710\n",
            "Epoch 140/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.2889 - accuracy: 0.9015\n",
            "Epoch 141/200\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.2432 - accuracy: 0.9205\n",
            "Epoch 142/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.2023 - accuracy: 0.9360\n",
            "Epoch 143/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.1964 - accuracy: 0.9345\n",
            "Epoch 144/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.1515 - accuracy: 0.9475\n",
            "Epoch 145/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.1382 - accuracy: 0.9495\n",
            "Epoch 146/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.1146 - accuracy: 0.9570\n",
            "Epoch 147/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.1446 - accuracy: 0.9455\n",
            "Epoch 148/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.1424 - accuracy: 0.9475\n",
            "Epoch 149/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.1343 - accuracy: 0.9495\n",
            "Epoch 150/200\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 0.1182 - accuracy: 0.9565\n",
            "Epoch 151/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.0989 - accuracy: 0.9630\n",
            "Epoch 152/200\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.1175 - accuracy: 0.9575\n",
            "Epoch 153/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.3422 - accuracy: 0.8990\n",
            "Epoch 154/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.3142 - accuracy: 0.8960\n",
            "Epoch 155/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.1783 - accuracy: 0.9435\n",
            "Epoch 156/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.1737 - accuracy: 0.9410\n",
            "Epoch 157/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.4181 - accuracy: 0.8680\n",
            "Epoch 158/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2007 - accuracy: 0.9370\n",
            "Epoch 159/200\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.1090 - accuracy: 0.9660\n",
            "Epoch 160/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.1242 - accuracy: 0.9610\n",
            "Epoch 161/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.2474 - accuracy: 0.9305\n",
            "Epoch 162/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.1519 - accuracy: 0.9450\n",
            "Epoch 163/200\n",
            "63/63 [==============================] - 4s 55ms/step - loss: 0.1734 - accuracy: 0.9490\n",
            "Epoch 164/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.3497 - accuracy: 0.8885\n",
            "Epoch 165/200\n",
            "63/63 [==============================] - 4s 57ms/step - loss: 0.3415 - accuracy: 0.8910\n",
            "Epoch 166/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.1839 - accuracy: 0.9445\n",
            "Epoch 167/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.0998 - accuracy: 0.9665\n",
            "Epoch 168/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.1164 - accuracy: 0.9605\n",
            "Epoch 169/200\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.0868 - accuracy: 0.9720\n",
            "Epoch 170/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1423 - accuracy: 0.9590\n",
            "Epoch 171/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.0977 - accuracy: 0.9715\n",
            "Epoch 172/200\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.0754 - accuracy: 0.9795\n",
            "Epoch 173/200\n",
            "63/63 [==============================] - 4s 62ms/step - loss: 0.8428 - accuracy: 0.7520\n",
            "Epoch 174/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.7509 - accuracy: 0.7540\n",
            "Epoch 175/200\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 0.4120 - accuracy: 0.8625\n",
            "Epoch 176/200\n",
            "63/63 [==============================] - 4s 68ms/step - loss: 0.3429 - accuracy: 0.8930\n",
            "Epoch 177/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.2342 - accuracy: 0.9230\n",
            "Epoch 178/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.1502 - accuracy: 0.9385\n",
            "Epoch 179/200\n",
            "63/63 [==============================] - 4s 60ms/step - loss: 0.2049 - accuracy: 0.9305\n",
            "Epoch 180/200\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.1523 - accuracy: 0.9480\n",
            "Epoch 181/200\n",
            "63/63 [==============================] - 4s 63ms/step - loss: 0.1531 - accuracy: 0.9505\n",
            "Epoch 182/200\n",
            "63/63 [==============================] - 3s 56ms/step - loss: 0.1206 - accuracy: 0.9580\n",
            "Epoch 183/200\n",
            "63/63 [==============================] - 4s 69ms/step - loss: 0.1143 - accuracy: 0.9595\n",
            "Epoch 184/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.0940 - accuracy: 0.9630\n",
            "Epoch 185/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.1448 - accuracy: 0.9500\n",
            "Epoch 186/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.1319 - accuracy: 0.9525\n",
            "Epoch 187/200\n",
            "63/63 [==============================] - 4s 58ms/step - loss: 0.1107 - accuracy: 0.9605\n",
            "Epoch 188/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.1140 - accuracy: 0.9555\n",
            "Epoch 189/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.0934 - accuracy: 0.9640\n",
            "Epoch 190/200\n",
            "63/63 [==============================] - 4s 66ms/step - loss: 0.0994 - accuracy: 0.9645\n",
            "Epoch 191/200\n",
            "63/63 [==============================] - 3s 53ms/step - loss: 0.0973 - accuracy: 0.9620\n",
            "Epoch 192/200\n",
            "63/63 [==============================] - 3s 54ms/step - loss: 0.0833 - accuracy: 0.9680\n",
            "Epoch 193/200\n",
            "63/63 [==============================] - 4s 64ms/step - loss: 0.1016 - accuracy: 0.9620\n",
            "Epoch 194/200\n",
            "63/63 [==============================] - 4s 59ms/step - loss: 0.1130 - accuracy: 0.9595\n",
            "Epoch 195/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.1286 - accuracy: 0.9570\n",
            "Epoch 196/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.1502 - accuracy: 0.9505\n",
            "Epoch 197/200\n",
            "63/63 [==============================] - 4s 67ms/step - loss: 0.0986 - accuracy: 0.9690\n",
            "Epoch 198/200\n",
            "63/63 [==============================] - 3s 55ms/step - loss: 0.0854 - accuracy: 0.9670\n",
            "Epoch 199/200\n",
            "63/63 [==============================] - 4s 56ms/step - loss: 0.0823 - accuracy: 0.9700\n",
            "Epoch 200/200\n",
            "63/63 [==============================] - 4s 65ms/step - loss: 0.0673 - accuracy: 0.9745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bc2444b1f00>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluating the models performance\n",
        "model.evaluate(xtest,ytest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Sl4ifQu9oN",
        "outputId": "1692439d-34a7-439a-8e04-a433e6e7ffd1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 4s 123ms/step - loss: 2.7420 - accuracy: 0.5300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.7419862747192383, 0.5299999713897705]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking models performance on image"
      ],
      "metadata": {
        "id": "DswI6YzvNBcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the image\n",
        "image = xtrain[5]\n",
        "\n",
        "# Convert the image to RGB format (CIFAR-10 images are in BGR format)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image using Matplotlib\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.imshow(image_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "tghZcrxPvBg9",
        "outputId": "65f3b51b-254e-4093-af8b-bfdf856e1b8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# resizing the image\n",
        "resized_image = cv2.resize(image, (75, 75))\n",
        "resized_image = np.expand_dims(resized_image, axis=0)\n",
        "resized_image.shape"
      ],
      "metadata": {
        "id": "pmgUZuIovnP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c8ade6-fa8d-457c-b706-4cdf6c6c9964"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 75, 75, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.predict(resized_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxyvokGIwCES",
        "outputId": "3b5669d5-bef8-49ef-e42c-153b3c0bb869"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = [\n",
        "    \"airplane\",\n",
        "    \"automobile\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\"\n",
        "]"
      ],
      "metadata": {
        "id": "3GwcRXGKwFlx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdTvvRTjw1SB",
        "outputId": "3bcd0cb0-429c-4c57-dde1-f60fc20bf415"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.6295969e-05, 9.9959546e-01, 3.1492068e-06, 2.1850862e-07,\n",
              "        3.2487762e-06, 1.1359498e-05, 4.0343763e-05, 2.8980769e-06,\n",
              "        9.1189904e-06, 2.7804618e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labelindex=np.argmax(output)"
      ],
      "metadata": {
        "id": "5BSbKeblwxLk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels[labelindex]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "z2diWHucwz7F",
        "outputId": "a4869604-83ed-4cfe-a07e-60baee69b1da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'automobile'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}